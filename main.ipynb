{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Manuscript Transmission as Speciation: Using Agent-Based Models and Bayesian Inference\n",
        "\n",
        "### Digital Approaches to Pre-Modern Texts and Manuscripts (Workshop)\n",
        "\n",
        "#### Jean-Baptiste Camps, Kelly Christensen, Ulysse Godreau, and Th茅o Moins\n",
        "\n",
        "12 June 2025"
      ],
      "metadata": {
        "id": "Q35XIHwrXpv_"
      },
      "id": "Q35XIHwrXpv_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent based models for manuscript transmission"
      ],
      "metadata": {
        "id": "hgNka96V5Hcm"
      },
      "id": "hgNka96V5Hcm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "rTYiLbOH5nO1"
      },
      "id": "rTYiLbOH5nO1"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LostMa-ERC/simMAtree_workshop.git\n",
        "\n",
        "import simMAtree_workshop.birth_death_utils as u\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from IPython.core.display import SVG, display\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import Counter\n",
        "import multiprocessing\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "os.chdir('simMAtree_workshop')"
      ],
      "metadata": {
        "id": "o18KZMzR50Z4"
      },
      "id": "o18KZMzR50Z4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A simple stochastic model of manuscripts transmission: the Birth and Death Model"
      ],
      "metadata": {
        "id": "GZady-QJ52o4"
      },
      "id": "GZady-QJ52o4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simulating *arbres r茅els* and constructing stemmata"
      ],
      "metadata": {
        "id": "JHpPB3sg6Jrs"
      },
      "id": "JHpPB3sg6Jrs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us first define the function that will simulate a single tree using the constant rate birth and death model"
      ],
      "metadata": {
        "id": "F2ZR2VN16Onj"
      },
      "id": "F2ZR2VN16Onj"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tree_bd(lda, mu, Nact, Ninact):\n",
        "    \"\"\"\n",
        "    Generate a tree (arbre r茅el) according to birth death model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lda : float\n",
        "        birth rate of new node per node per iteration\n",
        "    mu : float\n",
        "        death rate of nodes per node per per iteration\n",
        "    Nact : int\n",
        "        number of iterations of the active reproduction phase\n",
        "    Ninact : int\n",
        "        number of iterations of the pure death phase (lda is set to 0)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    G : nx.DiGraph()\n",
        "        networkx graph object of the generated tree with following node attributes:\n",
        "            'state' : boolean, True if node living at the end of simulation\n",
        "            'birth_time' : int\n",
        "            'death_time' : int\n",
        "\n",
        "    \"\"\"\n",
        "    currentID = 0\n",
        "    G = nx.DiGraph()\n",
        "    G.add_node(currentID)\n",
        "    living = {0:True}\n",
        "\n",
        "    birth_time = {0:0}\n",
        "    death_time = {}\n",
        "\n",
        "    pop = 1\n",
        "    prob_birth = lda\n",
        "    prob_death = mu\n",
        "\n",
        "    for t in range(Nact):\n",
        "        for current_node in list(G.nodes()):\n",
        "            r = np.random.rand()\n",
        "            if r < prob_birth and living[current_node]:\n",
        "                currentID += 1\n",
        "                G.add_node(currentID)\n",
        "                G.add_edge(current_node, currentID)\n",
        "                living[currentID] = True\n",
        "                pop += 1\n",
        "                birth_time[currentID] = t\n",
        "            if prob_birth < r and r < (prob_birth + prob_death) and living[current_node]:\n",
        "                living[current_node] =  False\n",
        "                pop -= 1\n",
        "                death_time[current_node] = t\n",
        "        if pop == 0:\n",
        "            break\n",
        "\n",
        "    for t in range(Ninact):\n",
        "        for current_node in list(G.nodes()):\n",
        "            r = np.random.rand()\n",
        "            if r <  prob_death and living[current_node]:\n",
        "                living[current_node] =  False\n",
        "                pop -= 1\n",
        "                death_time[current_node] = t + Nact\n",
        "            if pop == 0:\n",
        "                break\n",
        "\n",
        "    nx.set_node_attributes(G, living, 'state')\n",
        "    nx.set_node_attributes(G, birth_time, 'birth_time')\n",
        "    nx.set_node_attributes(G, death_time, 'death_time')\n",
        "    return G"
      ],
      "metadata": {
        "id": "CFqk6r7X6V6l"
      },
      "id": "CFqk6r7X6V6l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now generate a simulated manuscript tradition and play around with parameters, display the corresponding tree of the full tradition as well as the corresponding *stemma codicum*"
      ],
      "metadata": {
        "id": "VowfoiUz6dQP"
      },
      "id": "VowfoiUz6dQP"
    },
    {
      "cell_type": "code",
      "source": [
        "位 = 7.9*10**(-3)    # reproduction (=birth) rate\n",
        "渭 = 3.3*10**(-3)    # loss (=death) rate\n",
        "\n",
        "active_phase_duration = 1000\n",
        "decimation_phase_duration = 1000\n",
        "\n",
        "tree = generate_tree_bd(位, 渭, active_phase_duration , decimation_phase_duration)    # generate a simulated full tradition\n",
        "u.draw_tree(tree, 'arbre_reel')\n",
        "if any(nx.get_node_attributes(tree,'state').values()):      # check if tradition has any surviving witness\n",
        "    stemma = u.generate_stemma(tree)\n",
        "    u.draw_tree(stemma, 'stemma')\n",
        "    print('=== Full tradition ===')\n",
        "    display(SVG('arbre_reel.svg'))\n",
        "    print('=== Stemma ===')\n",
        "    display(SVG('stemma.svg'))\n",
        "else:\n",
        "    print('=== Full tradition ===')\n",
        "    display(SVG('arbre_reel.svg'))\n",
        "    print('resulting tradition has no survivng witnesses...Try again !')"
      ],
      "metadata": {
        "id": "Wlu03VcU6tDn"
      },
      "id": "Wlu03VcU6tDn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simulating manuscript populations over parameter space"
      ],
      "metadata": {
        "id": "GV2Q_J0C7GXZ"
      },
      "id": "GV2Q_J0C7GXZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know want to generate whole populations (*i.e.* many trees) for several values of the parameters 位 and 渭. we define a square region in the parameter space for ```lambda_min <= 位 <= lambda_max``` and ```mu_min <= 渭 <= mu_max``` spanned by ```lambda_mesh * mu_mesh``` evenly spaced points. For each pair ```(位,渭)```we genrate trad_nb different traditions, *i.e* artificial *texts*."
      ],
      "metadata": {
        "id": "ez_cUw3U7Kvn"
      },
      "id": "ez_cUw3U7Kvn"
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_min=6.5*10**(-3)\n",
        "lambda_max=8.5*10**(-3)\n",
        "mu_min=3.5*10**(-3)\n",
        "mu_max=4.5*10**(-3)\n",
        "\n",
        "lambda_mesh=5\n",
        "mu_mesh=5\n",
        "\n",
        "Nact=1000\n",
        "Ninact=1000\n",
        "\n",
        "# parameters values\n",
        "mu_range = np.linspace(mu_max, mu_min, mu_mesh)\n",
        "lambda_range = np.linspace(lambda_min, lambda_max, lambda_mesh)\n",
        "\n",
        "# parameter values as displayed in plots\n",
        "lambda_labels = [r'%.1f'%n for n in (10**(3))*lambda_range]\n",
        "mu_labels = [r'%.1f'%n for n in (10**(3))*mu_range]\n",
        "\n",
        "trad_nb=200             # number of generated traditions (=trees)\n",
        "path='bd_simulations'\n",
        "output_format='serialized'"
      ],
      "metadata": {
        "id": "PLVuAl698UdI"
      },
      "id": "PLVuAl698UdI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The whole set of simulations takes some minutes"
      ],
      "metadata": {
        "id": "X9LM9FZA8Z1s"
      },
      "id": "X9LM9FZA8Z1s"
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(f'{path}'):\n",
        "    os.mkdir(f'{path}')\n",
        "\n",
        "progress = tqdm(total = mu_mesh * lambda_mesh * trad_nb)\n",
        "for i in range(mu_mesh):\n",
        "    for j in range(lambda_mesh):\n",
        "        for k in range(trad_nb):\n",
        "            l = lambda_range[j]\n",
        "            m = mu_range[i]\n",
        "\n",
        "            point_path = f'{path}/lambda={lambda_labels[j]}_mu={mu_labels[i]}'\n",
        "\n",
        "            if not os.path.exists(point_path):\n",
        "                os.mkdir(point_path)\n",
        "\n",
        "            g = u.generate_tree_bd(l, m, Nact, Ninact)\n",
        "\n",
        "            if output_format == 'serialized':\n",
        "                os.system(f'touch {point_path}/{k}')\n",
        "                with open(f'{point_path}/{k}', 'wb') as f:\n",
        "                    pickle.dump(g, f)\n",
        "\n",
        "            if output_format == 'csv':\n",
        "                csv_dump(g, f'{point_path}/{k}')\n",
        "\n",
        "            progress.update(1)"
      ],
      "metadata": {
        "id": "WI6pTOjx8dUf"
      },
      "id": "WI6pTOjx8dUf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ploting phase diagrams"
      ],
      "metadata": {
        "id": "15AIDSjG887a"
      },
      "id": "15AIDSjG887a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We may now compute and plot various statistics on simulated data:\n",
        "\n",
        "- survival rate (proportion of trees with at least one surviving witness)\n",
        "- median number of witnesses of a tradition\n",
        "- stemmatic property such as the proportion of bifid stemmata"
      ],
      "metadata": {
        "id": "PHKS4wn59EN4"
      },
      "id": "PHKS4wn59EN4"
    },
    {
      "cell_type": "code",
      "source": [
        "def survival_rate(trees):\n",
        "    n_surv = 0\n",
        "    for g in trees:\n",
        "        if any(nx.get_node_attributes(g, 'state').values()):\n",
        "            n_surv += 1\n",
        "    return n_surv / len(trees)\n",
        "\n",
        "def median_witness_number(trees):\n",
        "    wit_nb = []\n",
        "    for g in trees:\n",
        "        wit_nb.append(u.witness_nb(g))\n",
        "    return np.mean(wit_nb)\n",
        "\n",
        "def bifidity_rate(trees):\n",
        "    n_bifid = 0\n",
        "    n_stemmata = 0\n",
        "    for g in trees:\n",
        "        if u.witness_nb(g) >= 3:\n",
        "            n_stemmata += 1\n",
        "            st = u.generate_stemma(g)\n",
        "            rd = st.degree(u.root(st))\n",
        "            if rd == 2:\n",
        "                n_bifid += 1\n",
        "    return n_bifid / n_stemmata\n",
        "\n",
        "u.plot_phase_diagram(path, lambda_labels, mu_labels, 200, survival_rate, 'survival rate of texts')\n",
        "u.plot_phase_diagram(path, lambda_labels, mu_labels, 200, median_witness_number, 'median number of witnesses', prec=0)\n",
        "u.plot_phase_diagram(path, lambda_labels, mu_labels, 200, bifidity_rate, 'proportion of bifid stemmata', prec=2)"
      ],
      "metadata": {
        "id": "b5LHW3oo9gHe"
      },
      "id": "b5LHW3oo9gHe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Abundance data"
      ],
      "metadata": {
        "id": "I6G15gLo_yZX"
      },
      "id": "I6G15gLo_yZX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For some specific values of the parameters 位 and 渭, we can now look at the distribution of the number of witnesses per texts (*abundance data*)"
      ],
      "metadata": {
        "id": "_YTu8mR0_2Vi"
      },
      "id": "_YTu8mR0_2Vi"
    },
    {
      "cell_type": "code",
      "source": [
        "位 = 7*10**(-3)\n",
        "渭 = 3*10**(-3)\n",
        "Ta = 1000\n",
        "Td = 1000\n",
        "\n",
        "witness_numbers = []\n",
        "for k in tqdm(range(1000)):\n",
        "    g = generate_tree_bd(位,渭,Ta,Td)\n",
        "    witness_numbers.append(u.witness_nb(g))\n",
        "\n",
        "x = Counter(witness_numbers).keys()\n",
        "y = Counter(witness_numbers).values()\n",
        "plt.semilogy(x,y,'+')"
      ],
      "metadata": {
        "id": "XDfHGasa_4u9"
      },
      "id": "XDfHGasa_4u9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A generalization of Birth-Death model: Yule Speciation model"
      ],
      "metadata": {
        "id": "4JxCjsAdALKR"
      },
      "id": "4JxCjsAdALKR"
    },
    {
      "cell_type": "code",
      "source": [
        "位 = 7.9*10**(-3)\n",
        "渭 = 3.3*10**(-3)\n",
        "纬 = .5*10**(-3)\n",
        "\n",
        "active_phase_duration = 1000\n",
        "decimation_phase_duration = 1000\n",
        "\n",
        "tree = u.generate_yule_tree(位,纬,渭, active_phase_duration, decimation_phase_duration)\n",
        "if any(nx.get_node_attributes(tree,'state').values()):      # check if tradition has any surviving witness\n",
        "    stemma = u.generate_stemma_yule(tree)\n",
        "    u.draw_tree_yule(stemma, 'stemma_yule')\n",
        "    print('=== Multi works stemma ===')\n",
        "    display(SVG('stemma_yule.svg'))\n",
        "else:\n",
        "    print('resulting tradition has no survivng witnesses...Try again !')"
      ],
      "metadata": {
        "id": "hN2TScZSA2k5"
      },
      "id": "hN2TScZSA2k5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Abundance data for Yule Model"
      ],
      "metadata": {
        "id": "hk72KW9IR7Vu"
      },
      "id": "hk72KW9IR7Vu"
    },
    {
      "cell_type": "code",
      "source": [
        "witnesses = u.generate_yule_pop(1*10**(-2), 12*10**(-3), 10**(-3), 3.3*10**(-3), 1000, 1000, 2)"
      ],
      "metadata": {
        "id": "N2sb3Hu-WjvP"
      },
      "id": "N2sb3Hu-WjvP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Counter(witnesses).keys()\n",
        "y = Counter(witnesses).values()\n",
        "plt.loglog(x,y,'+')"
      ],
      "metadata": {
        "id": "NTzmHYtfW_g6"
      },
      "id": "NTzmHYtfW_g6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulation Based Inference using SimMAtree"
      ],
      "metadata": {
        "id": "hfJ0fO_z9Fkf"
      },
      "id": "hfJ0fO_z9Fkf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Package installation"
      ],
      "metadata": {
        "id": "nrUSYsM6fAW5"
      },
      "id": "nrUSYsM6fAW5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86db4575",
      "metadata": {
        "id": "86db4575"
      },
      "outputs": [],
      "source": [
        "# Install simmatree directly from GitHub\n",
        "\n",
        "# !pip install git+https://github.com/LostMa-ERC/simMAtree.git\n",
        "\n",
        "# Issue on dependancies with colab! Run this 2 lines alternatively:\n",
        "!pip install git+https://github.com/LostMa-ERC/simMAtree.git --no-deps\n",
        "!pip install pandas numpy matplotlib seaborn pydantic click rich pyyaml sbi\n",
        "\n",
        "# Test installation\n",
        "!simmatree-test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Setup"
      ],
      "metadata": {
        "id": "B4ASvvqgXpEe"
      },
      "id": "B4ASvvqgXpEe"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Import simmatree functions directly\n",
        "from src.cli.config import Config\n",
        "from src.cli.generate import generate\n",
        "from src.cli.inference import inference\n",
        "from src.cli.score import score\n",
        "\n",
        "print(\"All imports successful!\")"
      ],
      "metadata": {
        "id": "pYgVPLqaXwC0"
      },
      "id": "pYgVPLqaXwC0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuration example"
      ],
      "metadata": {
        "id": "sVU-bAdHXygn"
      },
      "id": "sVU-bAdHXygn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define experiment configuration\n",
        "\n",
        "config_dict = {\n",
        "\n",
        "    # Type of model we are focusing on\n",
        "    'model': {\n",
        "        'name': 'Yule', # 'Yule' or 'BirthDeath' here\n",
        "        'config': {\n",
        "            'n_init': 300, # Initial number of trees\n",
        "            'Nact': 1000, # Number of active iterations\n",
        "            'Ninact': 1000, # Number of inactive iterations (only deaths)\n",
        "            'max_pop': 500000 # Maximum population size\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # For generation or scoring : the corresponding parameters (=rate) of a simulation\n",
        "    'params': {\n",
        "        'LDA': 0.3,\n",
        "        'lda': 0.008,\n",
        "        'gamma': 0.001,\n",
        "        'mu': 0.0033\n",
        "    },\n",
        "\n",
        "    # Configuration of the inference model\n",
        "    'inference': {\n",
        "        'name': 'SBI', # For the future : other inference method will be investigated\n",
        "        'config': {\n",
        "            'method': 'NPE',\n",
        "            'num_simulations': 200,\n",
        "            'num_rounds': 2,\n",
        "            'random_seed': 42,\n",
        "            'num_samples': 100,\n",
        "            'num_workers': 2,       # Reduced for Colab!\n",
        "            'device': 'cpu'\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create temporary directory for our experiment\n",
        "temp_dir = \"/content/\"\n",
        "config_file = os.path.join(temp_dir, 'Yule_example.yml')\n",
        "\n",
        "# Save configuration to YAML file\n",
        "with open(config_file, 'w') as f:\n",
        "    yaml.dump(config_dict, f, default_flow_style=False)\n",
        "\n",
        "# Parse configuration using simmatree's Config class\n",
        "config = Config(config_file)\n",
        "\n",
        "print(f\"Configuration saved to: {config_file}\")\n"
      ],
      "metadata": {
        "id": "Xl_qGV5wXwNM"
      },
      "id": "Xl_qGV5wXwNM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Abundance Data generation\n",
        "\n",
        "This simulates the copying and transmission process of manuscripts."
      ],
      "metadata": {
        "id": "gTSmdAL2csh1"
      },
      "id": "gTSmdAL2csh1"
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data_file = os.path.join(temp_dir, 'sample_data/synthetic_data.csv')\n",
        "\n",
        "# Use the generate function directly\n",
        "success = generate(\n",
        "    data_path=synthetic_data_file,\n",
        "    model=config.model,\n",
        "    parameters=config.params,\n",
        "    seed=42,\n",
        "    show_params=False\n",
        ")\n",
        "\n",
        "print(f\"\\nGeneration successful: {success}\")\n",
        "print(f\"Synthetic data saved to: {synthetic_data_file}\")\n",
        "\n",
        "# CLI equivalent:\n",
        "print(f\"\\n CLI equivalent: simmatree -c {config_file} generate -o {synthetic_data_file} --show-params\")"
      ],
      "metadata": {
        "id": "LwDskRohXwQs"
      },
      "id": "LwDskRohXwQs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and examine the synthetic data\n",
        "df = pd.read_csv(synthetic_data_file, sep=';')\n",
        "\n",
        "print(\"\\n First 10 rows:\")\n",
        "print(df.head(10))\n",
        "\n",
        "# Analyze witness distribution\n",
        "witness_counts = df.groupby('text_ID')['witness_ID'].count()\n",
        "\n",
        "print(f\"\\n Witness Distribution Statistics:\")\n",
        "print(f\"Mean number of witnesses per text: {witness_counts.mean():.2f}\")\n",
        "print(f\"Median number of witnesses per text: {witness_counts.median():.1f}\")\n",
        "print(f\"Max number of witnesses for one text: {witness_counts.max()}\")\n",
        "print(f\"Texts with only 1 witness: {(witness_counts == 1).sum()}\")"
      ],
      "metadata": {
        "id": "xOCmh0YlXwTu"
      },
      "id": "xOCmh0YlXwTu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create visualization of witness distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Histogram of witness counts per text\n",
        "axes[0].hist(witness_counts, bins=40, alpha=0.7, edgecolor='black')\n",
        "axes[0].set_xlabel('Number of Witnesses per Text')\n",
        "axes[0].set_ylabel('Number of Texts')\n",
        "axes[0].set_title('Distribution of Witnesses per Text')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Log-scale version for better visualization\n",
        "witness_freq = witness_counts.value_counts().sort_index()\n",
        "x_values = witness_freq.index.values\n",
        "y_values = witness_freq.values\n",
        "\n",
        "axes[1].plot(x_values, y_values, linestyle='--', marker='o',\n",
        "             markersize=6, linewidth=2, alpha=0.8)\n",
        "axes[1].set_xscale('log')\n",
        "axes[1].set_yscale('log')\n",
        "axes[1].set_xlabel('Number of Witnesses per Text (log scale)')\n",
        "axes[1].set_ylabel('Number of Texts (log scale)')\n",
        "axes[1].set_title('Distribution of Witnesses per Text (Log-Log Scale)')\n",
        "axes[1].grid(True, alpha=0.3, which='both')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hx2iH-GHXwda"
      },
      "id": "Hx2iH-GHXwda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Comparaison with Birth Death distribution"
      ],
      "metadata": {
        "id": "GVX9n1_FfL7R"
      },
      "id": "GVX9n1_FfL7R"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define another experiment configuration\n",
        "\n",
        "config_dict[\"model\"][\"name\"] = \"BirthDeath\"\n",
        "\n",
        "config_file_BD = os.path.join(temp_dir, 'BD_example.yml')\n",
        "\n",
        "# Save configuration to YAML file\n",
        "with open(config_file_BD, 'w') as f:\n",
        "    yaml.dump(config_dict, f, default_flow_style=False)\n",
        "\n",
        "# Parse configuration using simmatree's Config class\n",
        "config_BD = Config(config_file)\n",
        "\n",
        "\n",
        "synthetic_data_BD = os.path.join(temp_dir, 'sample_data/synthetic_data_BD.csv')\n",
        "success = generate(\n",
        "    data_path=synthetic_data_BD,\n",
        "    model=config_BD.model,\n",
        "    parameters=config_BD.params,\n",
        "    seed=42,\n",
        "    show_params=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "T6iZjqxMXwln"
      },
      "id": "T6iZjqxMXwln",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and examine the synthetic data\n",
        "df = pd.read_csv(synthetic_data_BD, sep=';')\n",
        "witness_counts = df.groupby('text_ID')['witness_ID'].count()\n",
        "\n",
        "print(f\"\\n Witness Distribution Statistics:\")\n",
        "print(f\"Mean number of witnesses per text: {witness_counts.mean():.2f}\")\n",
        "print(f\"Median number of witnesses per text: {witness_counts.median():.1f}\")\n",
        "print(f\"Max number of witnesses for one text: {witness_counts.max()}\")\n",
        "print(f\"Texts with only 1 witness: {(witness_counts == 1).sum()}\")\n"
      ],
      "metadata": {
        "id": "S3IpT5noQi2Z"
      },
      "id": "S3IpT5noQi2Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create visualization of witness distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Histogram of witness counts per text\n",
        "axes[0].hist(witness_counts, bins=40, alpha=0.7, edgecolor='black')\n",
        "axes[0].set_xlabel('Number of Witnesses per Text')\n",
        "axes[0].set_ylabel('Number of Texts')\n",
        "axes[0].set_title('Distribution of Witnesses per Text')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Log-scale version for better visualization\n",
        "witness_freq = witness_counts.value_counts().sort_index()\n",
        "x_values = witness_freq.index.values\n",
        "y_values = witness_freq.values\n",
        "\n",
        "axes[1].plot(x_values, y_values, linestyle='--', marker='o',\n",
        "             markersize=6, linewidth=2, alpha=0.8)\n",
        "axes[1].set_xscale('log')\n",
        "axes[1].set_yscale('log')\n",
        "axes[1].set_xlabel('Number of Witnesses per Text (log scale)')\n",
        "axes[1].set_ylabel('Number of Texts (log scale)')\n",
        "axes[1].set_title('Distribution of Witnesses per Text (Log-Log Scale)')\n",
        "axes[1].grid(True, alpha=0.3, which='both')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7fpHoBbHQknd"
      },
      "id": "7fpHoBbHQknd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Inference\n",
        "\n",
        "This will estimate the model parameters from the observed data.\n",
        "\n",
        "This may take a few minutes depending on the configuration."
      ],
      "metadata": {
        "id": "eX5uzpZUgTtC"
      },
      "id": "eX5uzpZUgTtC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up results directory\n",
        "results_dir = Path(temp_dir) / 'inference_results'\n",
        "results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Run inference using the Python function directly\n",
        "inference_data = inference(\n",
        "    csv_file=synthetic_data_file,\n",
        "    model=config.model,\n",
        "    backend=config.backend,\n",
        "    dir=results_dir,\n",
        "    csv_separator=';'\n",
        ")\n",
        "\n",
        "# List generated files\n",
        "result_files = list(results_dir.glob('*'))\n",
        "print(f\"\\n Generated files: {[f.name for f in result_files]}\")\n",
        "\n",
        "# CLI equivalent:\n",
        "print(f\"\\n CLI equivalent: simmatree -c {config_file} infer -i {synthetic_data_file} -o {results_dir}\")\n"
      ],
      "metadata": {
        "id": "uNN32pApgckq"
      },
      "id": "uNN32pApgckq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load posterior summary\n",
        "posterior_summary = pd.read_csv(results_dir / 'posterior_summary.csv')\n",
        "\n",
        "print(\" Posterior Summary Statistics:\")\n",
        "print(posterior_summary.round(6))\n",
        "\n",
        "# Compare with true parameters\n",
        "true_params = config.params\n",
        "estimated_params = posterior_summary['hpdi_95%'].values\n",
        "\n",
        "param_names = ['lda', 'mu']\n",
        "true_values = [true_params[name] for name in param_names]\n",
        "\n",
        "print(f\"\\n Parameter Comparison:\")\n",
        "print(f\"{'Parameter':<10} {'True Value':<12} {'HPDI Point':<12} {'Relative Error':<15}\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "for i, name in enumerate(param_names):\n",
        "    true_val = true_values[i]\n",
        "    estimated_val = estimated_params[i]\n",
        "    rel_error = abs(estimated_val - true_val) / true_val * 100\n",
        "    print(f\"{name:<10} {true_val:<12.6f} {estimated_val:<12.6f} {rel_error:<15.2f}%\")"
      ],
      "metadata": {
        "id": "jv1rqDZDju-l"
      },
      "id": "jv1rqDZDju-l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display generated plots\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Show posterior distributions\n",
        "plots_to_show = [\n",
        "    ('pairplot.png', 'Parameter Correlations and Posterior Distributions'),\n",
        "    ('posterior.png', 'Marginal Posterior Distributions'),\n",
        "    ('pp_summaries.png', 'Posterior Predictive Checks')\n",
        "]\n",
        "\n",
        "for plot_file, title in plots_to_show:\n",
        "    plot_path = results_dir / plot_file\n",
        "    if plot_path.exists():\n",
        "        print(f\"\\n{title}\")\n",
        "        img = mpimg.imread(plot_path)\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(title)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\" Plot not found: {plot_file}\")"
      ],
      "metadata": {
        "id": "sQ5oj3o3gcmp"
      },
      "id": "sQ5oj3o3gcmp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have here the ground truth, we can evaluate how accurate we are in our inference :"
      ],
      "metadata": {
        "id": "kselLnWkkpfD"
      },
      "id": "kselLnWkkpfD"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating inference performance against true parameters...\")\n",
        "\n",
        "params_BD = {'lda': config.params['lda'], 'mu': config.params['mu']}\n",
        "\n",
        "# Run scoring using the Python function directly\n",
        "score(param_dict=params_BD, results_dir=str(results_dir))\n",
        "\n",
        "# Load evaluation metrics\n",
        "metrics_file = results_dir / 'summary_metrics.csv'\n",
        "if metrics_file.exists():\n",
        "    metrics = pd.read_csv(metrics_file)\n",
        "    print(\"\\n Evaluation Metrics:\")\n",
        "    print(metrics.round(6))\n",
        "\n",
        "    print(f\"\\n Performance Summary:\")\n",
        "    print(f\"Root Mean Square Error (RMSE): {metrics['rmse'].iloc[0]:.6f}\")\n",
        "    print(f\"Normalized RMSE: {metrics['nrmse'].iloc[0]:.6f}\")\n",
        "    print(f\"Mean Relative Error: {metrics['mean_rel_error_pct'].iloc[0]:.2f}%\")\n",
        "    print(f\"Coverage Probability: {metrics['coverage_probability'].iloc[0]:.2f}\")\n",
        "else:\n",
        "    print(\" Evaluation metrics file not found.\")\n",
        "\n",
        "# CLI equivalent:\n",
        "print(f\"\\n CLI equivalent: simmatree -c {config_file} score -d {results_dir}\")"
      ],
      "metadata": {
        "id": "H7KbGTD8gcrL"
      },
      "id": "H7KbGTD8gcrL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display generated plots\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Show posterior distributions\n",
        "plots_to_show = [\n",
        "    ('pairplot.png', 'Parameter Correlations and Posterior Distributions'),\n",
        "    ('posterior.png', 'Marginal Posterior Distributions'),\n",
        "    ('relative_error.png', 'Relative error of estimates')\n",
        "]\n",
        "\n",
        "for plot_file, title in plots_to_show:\n",
        "    plot_path = results_dir / plot_file\n",
        "    if plot_path.exists():\n",
        "        print(f\"\\n{title}\")\n",
        "        img = mpimg.imread(plot_path)\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(title)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\" Plot not found: {plot_file}\")"
      ],
      "metadata": {
        "id": "aLdJo6IRgctq"
      },
      "id": "aLdJo6IRgctq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}